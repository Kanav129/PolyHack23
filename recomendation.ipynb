{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomendation System"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape data from user's Instagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip3 install selenium\n",
    "!apt-get -q update\n",
    "!apt install -yq chromium-chromedriver\n",
    "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
    "from selenium import webdriver\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "import pandas as pd\n",
    "driver = webdriver.Chrome('chromedriver', options=chrome_options)\n",
    "\n",
    "!pip3 install instaloader\n",
    "from instaloader import instaloader, Profile\n",
    "import time\n",
    "sys.setrecursionlimit(10000)\n",
    "from datetime import datetime\n",
    "from itertools import dropwhile, takewhile\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask user for their username and password to get access to user's instagram data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = instaloader.Instaloader()\n",
    "L.login(\"username\",\"password\") #username and log in here separated by comma for instagram account\n",
    "df=pd.DataFrame()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect data of every post on user's account such as caption, likes, comments and URl to post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for post in instaloader.Profile.from_username(L.context, 'user').get_posts():\n",
    "    df = df.append({'Caption': post.caption, 'Likes':post.likes, 'URL':post.url,'Comments':post.comments},ignore_index=True)\n",
    "    i=i+1\n",
    "    if i>400:\n",
    "        break   \n",
    "df.to_excel(\"user.xlsx\",index=False)\n",
    "print(\"Written to user.xlsx file\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and input URLs into an excel sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Excel file with URL only\n",
    "df2=df.drop(columns=['Caption','Likes','Comments'])\n",
    "df2.to_excel(\"user_mod.xlsx\",index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call google cloud vision API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade google-api-python-client\n",
    "!pip install google-cloud    \n",
    "!pip install google-cloud-vision\n",
    "import xlrd\n",
    "from google.cloud import vision\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send every URL to google vision to retrieve labels describing image and add the labels to the excel sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Application_Credentials = '.json' #Add API key here from Google Cloud Vision, its a .json file\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = Application_Credentials\n",
    "client = vision.ImageAnnotatorClient()\n",
    "image = vision.Image() \n",
    "\n",
    "loc= (\"user_mod.xlsx\")\n",
    "wb= xlrd.open_workbook(loc)\n",
    "sheet = wb.sheet_by_index(0)\n",
    "sheet.cell_value(0, 0)\n",
    "df3=pd.DataFrame()\n",
    "\n",
    "#loop through every url, retrieve the image  and send to google vision\n",
    "for i in range (sheet.nrows):\n",
    "    image_src_temp = sheet.cell_value(i,0)\n",
    "    image.source.image_uri = image_src_temp\n",
    "    response = client.label_detection(image=image)\n",
    "    labels = response.label_annotations\n",
    "    l=[]\n",
    "    for label in labels:\n",
    "        l.append(label.description)\n",
    "    s= ' '.join(l)\n",
    "    print(\"s\")\n",
    "    print(s)\n",
    "    df3=df3.append({'URL': image_src_temp, 'Labels':s}, ignore_index = True)\n",
    "df3.to_excel(\"Labels.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_copy = df3.copy()\n",
    "df3_copy = df3_copy.iloc[1:]\n",
    "df3_copy.reset_index(drop=True, inplace=True)\n",
    "df3_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#combine labels with origional excel file\n",
    "df['Labels']=df3_copy['Labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"Combined.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk, lda\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import warnings\n",
    "import re\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logging.getLogger(\"requests\").setLevel(logging.WARNING)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix formatting of labels to keep it universal throughout the application. Create 5 groups to divide labels and weight each label on how closely it correlates with every individual group. Create a nrw excel sheet with labels, URl and weightage for every group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df[\"Labels\"]\n",
    "def combine_bigram(labels): \n",
    "    tokens = re.findall('[A-Z][^A-Z]*', labels)\n",
    "    tokens = [t.replace(' ','') for t in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def tokenize_text(image_labels):\n",
    "    word_tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    return word_tokenizer.tokenize(image_labels)\n",
    "\n",
    "labels = labels.apply(combine_bigram)\n",
    "num_topic = 5\n",
    "vec_words = CountVectorizer(tokenizer =tokenize_text, decode_error='ignore')\n",
    "feature_words = vec_words.fit_transform(labels)\n",
    "\n",
    "model = lda.LDA(n_topics = num_topic, n_iter = 500,random_state = 1)\n",
    "model.fit(feature_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_word = model.topic_word_\n",
    "doc_topic = model.doc_topic_\n",
    "doc_topic = pd.DataFrame(doc_topic)\n",
    "df = df.join(doc_topic)\n",
    "\n",
    "\n",
    "topics = pd.DataFrame(topic_word)\n",
    "topics.columns = vec_words.get_feature_names()\n",
    "topic_transpose = topics.transpose()\n",
    "topic_transpose.to_excel(\"topic_word.xlsx\")\n",
    "df.to_excel(\"doc_topic.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top_words = 10\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vec_words.get_feature_names())[np.argsort(topic_dist)][:-n_top_words:-1]\n",
    "    print('Topic {}: {}'.format(i, ' '.join(topic_words)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of groups and their description."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "group 1: outdoors/adventure\n",
    "\n",
    "group 2: sightseeing\n",
    "\n",
    "group 3: music\n",
    "\n",
    "group 4: arts\n",
    "\n",
    "group 5: sports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign group names\n",
    "df = df.rename(columns={0: 'outdoors', 1: 'sightseeing', 2:'music',3:'arts',4:'sports'})\n",
    "\n",
    "output = df\n",
    "output.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
